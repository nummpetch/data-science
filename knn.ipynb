{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ในการจำแนกดูจากระยะห่างยูคลิเดียน euclidian หรืออาจะใช้ z-score เพื่อทำให้เป็นมตรฐานสำหรับข้อมูลต่อเนื่อง\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    with open('model/data/iris-dataset.csv', 'r') as f:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "def load_data_set(filename):\n",
    "     data = []\n",
    "    with open('model/data/iris-dataset.csv', 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            atributes = line.strip('\\n').split(',')\n",
    "            data.append([(x) for x in atributes])\n",
    "load_data_set(\"model/data/iris-dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert y to int\n",
    "def convert_y_to_int(filename):\n",
    "    data_set=[]\n",
    "    data = load_data_set(filename)\n",
    "    for row in (data):\n",
    "        data_row=[]\n",
    "        for i in row:\n",
    "            if(i == \"Iris-setosa\"):\n",
    "                i=1\n",
    "            elif(i == \"Iris-versicolor\"):\n",
    "                i=2\n",
    "            elif(i == \"Iris-virginica\"):\n",
    "                i=3\n",
    "            data_row.append(i)\n",
    "        data_set.append(data_row)\n",
    "    return (data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "convert_y_to_int(\"model/data/iris-dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data set\n",
    "def split_data_set(filename):\n",
    "    size_test_set =0.25\n",
    "    data_set = convert_y_to_int(filename)\n",
    "    train_set = []\n",
    "    test_set=[]\n",
    "    #validation use 0.25(train)+0.25(test)\n",
    "    validation_set = []\n",
    "\n",
    "    for i in range(0,int(len(data_set)*(1-size_test_set))):\n",
    "        train_set.append(data_set[i])\n",
    "    for i in range(int(len(data_set)*(1-size_test_set)),len(data_set)):\n",
    "        test_set.append(data_set[i])\n",
    "    for i in range(int(len(data_set)*(1-size_test_set)*0.75),int(len(data_set)-(len(data_set)*(1-size_test_set)*0.25))):\n",
    "         validation_set.append(data_set[i])\n",
    "    return(train_set,test_set,validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(p1,p2):\n",
    "    distance = 0\n",
    "    for i in range(len(p1)-1):\n",
    "        distance += pow(float(p1[i])-float(p2[i]), 2)\n",
    "    return math.sqrt(distance)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortSecond(val): \n",
    "    return val[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor(data,k):\n",
    "    data_set_k =[]\n",
    "    for i in range(k):\n",
    "        data_set_k.append(data[i])\n",
    "    return(data_set_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_response(data_set_k):\n",
    "    class_set=[]\n",
    "    len_attribute=len(data_set_k[0][0])-1\n",
    "    for i in range(len(data_set_k)):\n",
    "        class_set.append(data_set_k[i][0][len_attribute])\n",
    "    return(max(class_set, key=class_set.count))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    len_attribute=len(testSet[0])-1\n",
    "    for x in range(len(testSet)):\n",
    "        if (int(testSet[x][len_attribute]) == int(predictions[x])):\n",
    "            correct += 1\n",
    "    return round((correct/float(len(testSet))) * 100.0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train_set,test_set,k):\n",
    "    neighbors =[]\n",
    "    for i in range(len(train_set)):\n",
    "        distance = euclidian_distance(train_set[i],test_set)\n",
    "        neighbors.append((train_set[i],distance))\n",
    "        \n",
    "    #sorting find nearest neighbor\n",
    "    neighbors.sort(key=sortSecond)\n",
    "        \n",
    "    #get class from k neighbor\n",
    "    data_set_k=get_neighbor(neighbors,k)\n",
    "    class_prediction=predict_response(data_set_k)\n",
    "    return(class_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(k):\n",
    "    predict_set=[]\n",
    "    for i in range(len(test_set)):\n",
    "        class_predict=knn(train_set,test_set[i],k)\n",
    "        predict_set.append(class_predict)\n",
    "    return getAccuracy(test_set,predict_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  1\n",
      "Accuracy:  84.211\n",
      "------\n",
      "k:  2\n",
      "Accuracy:  84.211\n",
      "------\n",
      "k:  3\n",
      "Accuracy:  71.053\n",
      "------\n",
      "k:  4\n",
      "Accuracy:  76.316\n",
      "------\n",
      "k:  5\n",
      "Accuracy:  71.053\n",
      "------\n",
      "k:  6\n",
      "Accuracy:  73.684\n",
      "------\n",
      "k:  7\n",
      "Accuracy:  73.684\n",
      "------\n",
      "k:  8\n",
      "Accuracy:  73.684\n",
      "------\n",
      "k:  9\n",
      "Accuracy:  65.789\n",
      "------\n",
      "k:  10\n",
      "Accuracy:  68.421\n",
      "------\n",
      "k:  11\n",
      "Accuracy:  63.158\n",
      "------\n",
      "k:  12\n",
      "Accuracy:  63.158\n",
      "------\n",
      "k:  13\n",
      "Accuracy:  60.526\n",
      "------\n",
      "k:  14\n",
      "Accuracy:  63.158\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "train_set,test_set,validation_set = split_data_set(\"model/data/iris-dataset.csv\")\n",
    "for k in range(1,15):\n",
    "    acc=get_knn(k)\n",
    "    print(\"k: \",k)\n",
    "    print(\"Accuracy: \",acc)\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
